---
title: Augmenter les performances de Nginx
description: Un petit article sur comment optimiser votre Nginx üòé
author:
    name: flapili
    avatar: flapili.webp
archived: false
image:
    src: NGINX-logo.png
    alt: logo de Nginx
tags: nginx;performances;optimisations
createdAt: 2021-05-16T15:46:23.714Z
---



## Pr√©ambule
- Ce tutoriel s'adresse aux gens sous GNU/Linux, il a √©t√© fait sous Debian 10 (avec un compte root).
- Il est possible que certaines commandes changent suivant votre distribution (et surtout de votre package manager) ou qu'il y ai besoin d'utiliser sudo.

## Installation des pr√©requis

<client-only>
    <div style="display: flex;justify-content:center;">
        <div class="termy">
            // installation des paquets pr√©requis ...
            $ apt update && apt install -y apt-transport-https ca-certificates curl gnupg2 software-properties-common
            ---> 100%
    </div>
</div>
</client-only>


## Installation de Nginx
On va ici utiliser directement les repositories de Nginx plut√¥t que ceux de Debian:

<client-only>
    <div style="display: flex;justify-content:center;">
        <div class="termy">
            // On va dans /tmp pour ne pas polluer notre ~home
            $ cd /tmp
            // On t√©l√©charge la clef
            $ wget https://nginx.org/keys/nginx_signing.key
            ---> 100%
            // On ajoute la clef pr√©cedement t√©l√©charg√©e
            $ apt-key add nginx_signing.key
            OK
            // On ajoute le repository de Nginx dans nos sources
            nano /etc/apt/sources.list.d/nginx.list
        </div>
    </div>
</client-only>

√† ajouter dans `/etc/apt/sources.list.d/nginx.list`
```
deb http://nginx.org/packages/mainline/debian buster nginx
deb-src https://nginx.org/packages/mainline/debian/ buster nginx
```

<client-only>
    <div style="display: flex;justify-content:center;">
        <div class="termy">
            $ apt update && apt install nginx
            ---> 100%
        </div>
    </div>
</client-only>

## Tuning de la configuration
Le point d'entr√©e de la configuration de Nginx est `/etc/nginx/nginx.conf`.<br>


## block racine

### worker_processes
Par d√©faut cette directive est √† 1, cel√† veux dire qu'il n'y a qu'un seul processus Nginx qui tourne, or de nos jours il est fr√©quent d'avoir des serveurs avec plus d'un core CPU.<br>
Malheureusement un processus Nginx n'est pas capable d'utiliser plus d'un core √† la fois ...<br>
Heureusement il est possible de faire tourner plusieurs processus de Nginx, en plus c'est super simple avec la directive `worker_processes`.

Le plus simple est de d√©finir `worker_processes` √† `auto`, cela va cr√©er autant de processus Nginx qu'il y a de core.

**Mais attends ?!**<br>
Comment c'est possible que plusieurs processus √©coutent sur le m√™me port ?

1. Nginx se lance une 1√®re fois en root (bien oblig√© pour √©couter sur les ports inf√©rieurs √† 1024 sans utiliser CAP_NET_BIND_SERVICE) et bind les sockets (√©coute sur le port 80 par exemple pour faire simple), on l'appelle `master`.
2. Puis il se d√©double en autant d'exemplaire que d√©fini par la directive `worker_processes`, se sont des `workers`.
3. Les `workers` changent d'utilisateur conform√©ment √† la directive `user`.

L'astuce r√©side dans le fork (le d√©doublage), le processus p√®re partage toutes les ressources qu'il a √† son nouveau fils, y compris fichiers et ports ouverts.<br>
*en r√©alit√© fichier et ports sont la m√™me chose sous Unix, se sont des files descriptor ... mais √ßa c'est un autre sujet.*
<div style="text-align: center;">
    <img
        src="/posts/nginx-master-workers.png"
        alt="Illustration nginx master / workers"
        loading="lazy"
        style="max-width: 100%;min-width: 50%;border-radius:10px;border: solid 1px black"
    >
</div>


## block events

### multi_accept
si `multi_accept` est √† `on` un processus worker va accepter toutes les nouvelles connexions en m√™me temps, au contraire si si la directive est √† `off` il ne pourra en accepter qu'une √† la fois.<br />
*Par d√©faut cette directive est sur `off`.*

### worker_connections
r√®gle le nombre maximal de connexions simultan√©es qu'un worker peut ouvrir en m√™me temps.<br />
Il faut garder √† l'esprit que √ßa inclue toutes les connexions (connexion avec un backend proxi√© par exemple).

On peut augmenter ce param√®tre √† 1024 sans trop de soucis.<br />
*Par d√©faut ce param√®tre est √† `512` requ√™tes simultan√©es par workers.*

## block http

### sendfile
Utilise l'appel kernel [sendfile](http://manpages.ubuntu.com/manpages/trusty/man2/sendfile.2freebsd.html) dans le cas o√π nginx doit servir des fichiers statiques, plut√¥t qu'une combinaison de write et read.
*Par d√©faut ce param√®tre est √† `off`.*

### aio
Permet de ne pas bloquer la boucle d'√©v√©nement du processus worker dans le cas o√π une op√©ration bloquante est en cours (lecture de fichier par exemple)<br />
*Par d√©faut cette directive est √† `off`.*

### tcp_nopush
Permet d'envoyer les ent√™tes HTTP et le d√©but (ou la totalit√©) du fichier en un seul packet.<br>
*Par d√©faut cette directive est √† `off`.*

### gzip
Permet de compresser la r√©ponse renvoy√©e par Nginx.
*Par d√©faut cette directive est √† `off`.*

### gzip_proxied
Permet de compresser les r√©ponses pour des requ√™tes proxi√©es suivant les ent√™tes HTTP<br />
Je conseille d'utiliser `any` pour tout le temps activer la compression.
*Par d√©faut cette directive est √† `off`.*

### gzip_comp_level
Permet de plus ou moins compresser la r√©ponse, une valeur √©lev√©e entrainera une consommation CPU plus importante<br/>
Le juste milieu entre usage CPU et usage r√©seau se situe au alentour de `5`/`6`.<br />
*Par d√©faut le niveau est √† `1`.*


## Mise en cache

<infobox>
    Ce cache ne s'applique que dans le cadre de ressources proxi√©es.
</infobox>

<warningbox card-style="margin-top:10px;">
    Mettre en cache des donn√©es venant de votre API peux avoir des effets ind√©sirables.
</warningbox>

dans `etc/nginx/nginx.conf`
```nginx
proxy_cache_path /tmp/cache levels=1:2 keys_zone=my_cache:10m inactive=10m;
```
Cette directive permet de cr√©er une zone de cache nomm√©e `my_cache` qui a un index de 10mb (ce qui doit √™tre suffisant pour le commun des mortels)<br />
`/tmp/cache` d√©fini o√π le cache sera √©crit sur le disque, dans le cas de forte activit√© le kernel Linux devrait √™tre assez malin pour mettre les fichiers dans un cache LRU, pas besoin donc d'un montage de type tmpfs<br />
`inactive` permet de stipuler au bout de combien de temps les fichiers de cache devraient √™tre purger si le cache n'est pas utilis√©.

dans `/etc/nginx/sites-enabled/monsite.fr.conf`
```nginx
proxy_cache my_cache;
proxy_cache_methods GET HEAD;
proxy_cache_valid 200 302 10s;
add_header X-Cache-Status $upstream_cache_status;
```
- `proxy_cache` permet de dire qu'on va utiliser le cache nomm√© `my_cache`, d√©fini dans le block http juste au dessus.
- `proxy_cache_methods` permet de dire sur quelles methodes on va mettre en place le cache. *par d√©faut se sont les m√©thodes GET et HEAD qui sont misent en cache.*
- `proxy_cache_valid` permet de d√©finir quels status code seront mis en cache et pour combien de temps. Par example `proxy_cache_valid 200 302 10s;` met en cache toutes les r√©ponses 200 et 302 de l'api proxi√©e avec une dur√©e de validit√© de 10 secondes.
- `add_header` n'est pas une directive propre √† la mise en cache, cependant la variable `upstream_cache_status` indique si la requ√™te a √©t√© ou non tir√©e du cache, cela nous permet donc de savoir si les donn√©es viennent de l'api ou du cache.

## ratelimit

dans `etc/nginx/nginx.conf` on va d√©finir tout comme pour le cache une zone de ratelimit
```nginx
limit_req_zone $binary_remote_addr zone=1reqPer1Second:10m rate=1r/s;
```
On cr√©e donc une zone qui s'appelle `1reqPer1Second` avec comme clef de dictionnaire `$binary_remote_addr` et comme taille maximale du dictionnaire 10mb.<br />

dans `/etc/nginx/sites-enabled/monsite.fr.conf`
```nginx
limit_req zone=1reqPer1Second burst=50 nodelay;
limit_req_status 429;
```
- `limit_req zone=1reqPer1Second burst=50 nodelay;` permet de dire qu'on va utiliser la zone pr√©c√©dement cr√©√©e, pour `burst` il va falloir utiliser l'analogie du [seau perc√©](https://fr.wikipedia.org/wiki/Seau_perc√©)<br />
    - On prends un seau qui peut contenir 50 unit√©es (des requ√™tes ici)
    - toutes les secondes une unit√© s'√©coule du seau
    - quand le seau arrive √† 50 il d√©borde, la requ√™te n'est pas trait√©e
- `limit_req_status` d√©fini le status de la r√©ponse renvoy√© par Nginx dans le cas d'un ratelimit

## Bonus: redirection en HTTPS sur tous vos vhosts

On va rediriger toutes les requ√™tes qui sont sur le port 80 (http) vers le port 443 (https)<br>
```nginx
server {
    listen 80;
    listen [::]:80;
    server_name _;
    return 301 https://$host$request_uri;
}
```
<infobox>
    Il est possible de modifier ce comportement pour un vhost en mettant le bon `server_name`.
</infobox>


## R√©capitulation
`/etc/nginx/nginx.conf`
```nginx

user  nginx;
worker_processes  auto;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

events {
	multi_accept on;
	worker_connections  1024;
}

http {
	limit_req_zone $binary_remote_addr zone=1reqPer1Second:10m rate=1r/s;
	proxy_cache_path /tmp/cache levels=1:2 keys_zone=my_cache:10m inactive=10m;
	##
	# Basic Settings
	##

	sendfile on;
	aio on;
	tcp_nopush on;
	types_hash_max_size 2048;

	include /etc/nginx/mime.types;
	default_type application/octet-stream;

	##
	# SSL Settings
	##

	# ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
	ssl_protocols TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE
	ssl_prefer_server_ciphers on;

	##
	# Logging Settings
	##

	access_log /var/log/nginx/access.log;
	error_log /var/log/nginx/error.log;

	##
	# Gzip Settings
	##

	gzip on;
	gzip_proxied any;
	gzip_comp_level 6;
	gzip_http_version 1.1;
	gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

	##
	# Virtual Host Configs
	##
	server {
		listen 80;
		listen [::]:80;
		server_name _;
		return 301 https://$host$request_uri;
	}
	include /etc/nginx/conf.d/*.conf;
	include /etc/nginx/sites-enabled/*.conf;
}
```

`/etc/nginx/sites-enabled/monsite.fr.conf`
```nginx

server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;
    server_name monsite.fr www.monsite.fr;

    location / {

        limit_req zone=1reqPer1Second burst=50 nodelay;
        limit_req_status 429;

        proxy_cache my_cache;
        proxy_cache_methods GET HEAD;
        proxy_cache_valid 200 302 10s;
        add_header X-Cache-Status $upstream_cache_status;
        proxy_pass http://unix:/tmp/monsite.fr.sock;
        include /etc/nginx/proxy_params;
    }
    ssl_certificate /etc/letsencrypt/live/flapili.fr/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/flapili.fr/privkey.pem;
}
```
